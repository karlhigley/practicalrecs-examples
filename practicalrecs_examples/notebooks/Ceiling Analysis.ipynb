{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import time\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pybloomfilter as pbf\n",
    "import torch as th\n",
    "from practicalrecs_examples.ann_search import *\n",
    "from practicalrecs_examples.dithering import *\n",
    "from practicalrecs_examples.filtering import *\n",
    "from practicalrecs_examples.matrix_factorization import *\n",
    "from practicalrecs_examples.notebooks.utils import *\n",
    "from practicalrecs_examples.pipeline import *\n",
    "from pytorch_lightning import seed_everything\n",
    "from ranking_metrics_torch.cumulative_gain import ndcg_at\n",
    "from ranking_metrics_torch.precision_recall import precision_at, recall_at\n",
    "from torch_factorization_models.movielens import MovielensDataModule\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same seed used to create splits in training\n",
    "seed_everything(42)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"../models/mf_example.pt\")\n",
    "\n",
    "if th.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens_module = MovielensDataModule(\"../datasets/ml-20m/\", batch_size=128)\n",
    "movielens_module.setup()\n",
    "\n",
    "movielens_module.dataset.to_(device=model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = movielens_module.val_dataloader(by_user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = movielens_module.train_dataloader(by_user=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Nearest Neighbor Search Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = model.hparams.embedding_dim\n",
    "item_vectors = np.array(model.item_embeddings.weight.cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_index = build_nn_search_index(item_vectors, dim, \"Flat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_index = build_nn_search_index(item_vectors, dim, \"IVF1024,PQ32\", nprobe=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Bloom Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138287/138287 [00:40<00:00, 3405.51it/s]\n"
     ]
    }
   ],
   "source": [
    "bloom_filters = build_bloom_filters(\n",
    "    tqdm(train_dataloader.dataset),\n",
    "    expected_items=10,\n",
    "    fp_rate=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Raw Model-Only Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [01:23<00:00, 12.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Pass in the number of recs to evaluate here?\n",
    "model_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    model.eval_predict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0152\n",
      "Recall: 0.4629\n",
      "NDCG: 0.2005\n"
     ]
    }
   ],
   "source": [
    "print_metrics(model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Initial Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = model.hparams.num_users\n",
    "num_items = model.hparams.num_items\n",
    "num_candidates = 250\n",
    "num_recs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move this to a method param?\n",
    "model.eval_cutoff = num_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move this into the library?\n",
    "def pipeline_fn(pipeline):\n",
    "    def pipeline_predict(user_ids, num_items):\n",
    "        user_scores = []\n",
    "        for user_id in user_ids:\n",
    "            user_id = int(user_id.cpu().item())\n",
    "\n",
    "            interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "            item_ids = interactions.indices()[1]\n",
    "\n",
    "            scores = pipeline.recommend(user_id, item_ids)\n",
    "\n",
    "            user_scores.append(scores)\n",
    "\n",
    "        return th.stack(user_scores)\n",
    "    \n",
    "    return pipeline_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dithering_eps=5.0\n",
    "\n",
    "default_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        UserAvgEmbeddingFetcher(model),\n",
    "        ANNSearch(approx_index, num_items, num_candidates),\n",
    "    ],\n",
    "    filtering = [\n",
    "        BloomFilter(bloom_filters),\n",
    "        CandidatePadding(num_items, num_candidates),\n",
    "    ],\n",
    "    scoring = [\n",
    "        MatrixFactorizationScoring(model),\n",
    "    ],\n",
    "    ordering = [\n",
    "        DitheredOrdering(num_recs, epsilon=dithering_eps),\n",
    "    ]\n",
    ")\n",
    "\n",
    "base_pipeline_builder = RecsPipelineBuilder(defaults=default_stages)\n",
    "\n",
    "base_pipeline = base_pipeline_builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [04:26<00:00,  4.05it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(base_pipeline)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNSearch: 47.94s (0.35 ms/user)\n",
      "MatrixFactorizationScoring: 45.03s (0.33 ms/user)\n",
      "DitheredOrdering: 29.58s (0.21 ms/user)\n",
      "BloomFilter: 11.90s (0.09 ms/user)\n",
      "UserAvgEmbeddingFetcher: 6.56s (0.05 ms/user)\n",
      "CandidatePadding: 6.53s (0.05 ms/user)\n"
     ]
    }
   ],
   "source": [
    "print_times(base_pipeline, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0058\n",
      "Recall: 0.2163\n",
      "NDCG: 0.1581\n"
     ]
    }
   ],
   "source": [
    "print_metrics(pipeline_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Idealized Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learned user embedding, exact NN search, idealized results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_retrieval_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        UserEmbeddingFetcher(model),\n",
    "        IdealizedANNSearch(val_dataloader.dataset, exact_index, num_items, num_candidates),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ideal_retrieval = base_pipeline_builder.build(overrides=ideal_retrieval_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:30<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "ideal_retrieval_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(ideal_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0115\n",
      "Recall: 0.4344\n",
      "NDCG: 0.2108\n"
     ]
    }
   ],
   "source": [
    "print_metrics(ideal_retrieval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Idealized Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_filtering_stages = RecsPipelineStages(\n",
    "    filtering = [\n",
    "        IdealizedFilter(train_dataloader.dataset),\n",
    "        CandidatePadding(num_items, num_candidates),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ideal_filtering = base_pipeline_builder.build(overrides=ideal_filtering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1081 [00:00<?, ?it/s]/home/karl/Projects/practicalrecs-examples/practicalrecs_examples/filtering.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidates = th.tensor(user_recs.candidates, dtype=th.long)\n",
      "100%|██████████| 1081/1081 [05:09<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "ideal_filtering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(ideal_filtering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0105\n",
      "Recall: 0.2857\n",
      "NDCG: 0.1616\n"
     ]
    }
   ],
   "source": [
    "print_metrics(ideal_filtering_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omit filtering entirely (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_filtering_stages = RecsPipelineStages(\n",
    "    filtering = [\n",
    "        CandidatePadding(num_items, num_candidates),\n",
    "    ]\n",
    ")\n",
    "\n",
    "no_filtering = base_pipeline_builder.build(overrides=no_filtering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [04:15<00:00,  4.23it/s]\n"
     ]
    }
   ],
   "source": [
    "no_filtering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(no_filtering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0089\n",
      "Recall: 0.2587\n",
      "NDCG: 0.1488\n"
     ]
    }
   ],
   "source": [
    "print_metrics(no_filtering_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Idealized Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_scoring_stages = RecsPipelineStages(\n",
    "    scoring = [\n",
    "        IdealizedMatrixFactorizationScoring(model, val_dataloader.dataset),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ideal_scoring = base_pipeline_builder.build(overrides=ideal_scoring_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:05<00:00,  3.54it/s]\n"
     ]
    }
   ],
   "source": [
    "ideal_scoring_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(ideal_scoring)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0072\n",
      "Recall: 0.2816\n",
      "NDCG: 0.4054\n"
     ]
    }
   ],
   "source": [
    "print_metrics(ideal_scoring_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Idealized Ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order descending by score (omitting dithering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_ordering_stages = RecsPipelineStages(ordering = [])\n",
    "\n",
    "ideal_ordering = base_pipeline_builder.build(overrides=ideal_ordering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [04:02<00:00,  4.45it/s]\n"
     ]
    }
   ],
   "source": [
    "ideal_ordering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(ideal_ordering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0058\n",
      "Recall: 0.2163\n",
      "NDCG: 0.1679\n"
     ]
    }
   ],
   "source": [
    "print_metrics(ideal_ordering_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Idealized Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_everything_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        UserEmbeddingFetcher(model),\n",
    "        IdealizedANNSearch(val_dataloader.dataset, exact_index, num_items, num_candidates),\n",
    "    ],\n",
    "    filtering = [\n",
    "        IdealizedFilter(train_dataloader.dataset),\n",
    "        CandidatePadding(num_items, num_candidates),\n",
    "    ],\n",
    "    scoring = [\n",
    "        IdealizedMatrixFactorizationScoring(model, val_dataloader.dataset),\n",
    "    ],\n",
    "    ordering = []\n",
    ")\n",
    "\n",
    "ideal_everything = base_pipeline_builder.build(overrides=ideal_everything_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_everything_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(ideal_everything)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(ideal_everything_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Improved Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138287/138287 [00:46<00:00, 2960.95it/s]\n"
     ]
    }
   ],
   "source": [
    "improved_bloom_filters = build_bloom_filters(\n",
    "    tqdm(train_dataloader.dataset),\n",
    "    expected_items=100,\n",
    "    fp_rate=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_filtering_stages = RecsPipelineStages(\n",
    "    filtering = [\n",
    "        BloomFilter(improved_bloom_filters),\n",
    "        CandidatePadding(num_items, num_candidates),\n",
    "    ]\n",
    ")\n",
    "\n",
    "improved_filtering = base_pipeline_builder.build(overrides=improved_filtering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:11<00:00,  3.47it/s]\n"
     ]
    }
   ],
   "source": [
    "improved_filtering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(improved_filtering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0102\n",
      "Recall: 0.2836\n",
      "NDCG: 0.1611\n"
     ]
    }
   ],
   "source": [
    "print_metrics(improved_filtering_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Baseline For Further Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        UserAvgEmbeddingFetcher(model),\n",
    "        ANNSearch(approx_index, num_items, num_candidates),\n",
    "    ],\n",
    "    filtering = [\n",
    "        BloomFilter(improved_bloom_filters),\n",
    "        CandidatePadding(num_items, num_candidates),\n",
    "    ],\n",
    "    scoring = [\n",
    "        MatrixFactorizationScoring(model),\n",
    "    ],\n",
    "    ordering = [\n",
    "        DitheredOrdering(num_recs, epsilon=dithering_eps),\n",
    "    ]\n",
    ")\n",
    "\n",
    "improved_filtering_pipeline_builder = RecsPipelineBuilder(defaults=default_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_retrieval = improved_filtering_pipeline_builder.build(overrides=ideal_retrieval_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:13<00:00,  3.44it/s]\n"
     ]
    }
   ],
   "source": [
    "ideal_retrieval_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(ideal_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0207\n",
      "Recall: 0.5657\n",
      "NDCG: 0.2359\n"
     ]
    }
   ],
   "source": [
    "print_metrics(ideal_retrieval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_scoring = improved_filtering_pipeline_builder.build(overrides=ideal_scoring_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:02<00:00,  3.57it/s]\n"
     ]
    }
   ],
   "source": [
    "ideal_scoring_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(ideal_scoring)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0149\n",
      "Recall: 0.4165\n",
      "NDCG: 0.4253\n"
     ]
    }
   ],
   "source": [
    "print_metrics(ideal_scoring_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_ordering = improved_filtering_pipeline_builder.build(overrides=ideal_ordering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [04:03<00:00,  4.44it/s]\n"
     ]
    }
   ],
   "source": [
    "ideal_ordering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(ideal_ordering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0102\n",
      "Recall: 0.2836\n",
      "NDCG: 0.1680\n"
     ]
    }
   ],
   "source": [
    "print_metrics(ideal_ordering_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learned user embedding, exact NN search, no idealization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_exact_nonideal_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        UserEmbeddingFetcher(model),\n",
    "        ANNSearch(exact_index, num_items, num_candidates),\n",
    "        UserAvgEmbeddingFetcher(model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "learned_exact_nonideal_retrieval = improved_filtering_pipeline_builder.build(overrides=learned_exact_nonideal_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_exact_nonideal_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(learned_exact_nonideal_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(learned_exact_nonideal_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learned user embedding, approx NN search, no idealization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_approx_nonideal_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        UserEmbeddingFetcher(model),\n",
    "        ANNSearch(approx_index, num_items, num_candidates),\n",
    "        UserAvgEmbeddingFetcher(model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "learned_approx_nonideal_retrieval = improved_filtering_pipeline_builder.build(overrides=learned_approx_nonideal_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_approx_nonideal_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(learned_approx_nonideal_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(learned_approx_nonideal_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaged user embedding, exact NN search, no idealization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_exact_nonideal_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        UserAvgEmbeddingFetcher(model),\n",
    "        ANNSearch(exact_index, num_items, num_candidates),\n",
    "    ]\n",
    ")\n",
    "\n",
    "avg_exact_nonideal_retrieval = improved_filtering_pipeline_builder.build(overrides=avg_exact_nonideal_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_exact_nonideal_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(avg_exact_nonideal_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(avg_exact_nonideal_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaged user embedding, approx NN search, no idealization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_approx_nonideal_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        UserAvgEmbeddingFetcher(model),\n",
    "        ANNSearch(approx_index, num_items, num_candidates),\n",
    "    ]\n",
    ")\n",
    "\n",
    "avg_approx_nonideal_retrieval = improved_filtering_pipeline_builder.build(overrides=avg_approx_nonideal_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_approx_nonideal_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(avg_approx_nonideal_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(avg_approx_nonideal_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item embeddings, exact NN search, idealized results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_exact_ideal_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        ItemEmbeddingsFetcher(model),\n",
    "        UseItemEmbeddingsAsUserEmbeddings(),\n",
    "        IdealizedANNSearch(val_dataloader.dataset, exact_index, num_items, num_candidates),\n",
    "        # Re-fetching user average embeddings keeps modified retrieval from affecting scoring\n",
    "        UserAvgEmbeddingFetcher(model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "items_exact_ideal_retrieval = improved_filtering_pipeline_builder.build(overrides=items_exact_ideal_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_exact_ideal_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(items_exact_ideal_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(items_exact_ideal_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Item embeddings, exact NN search, no idealization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_exact_nonideal_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        ItemEmbeddingsFetcher(model),\n",
    "        UseItemEmbeddingsAsUserEmbeddings(),\n",
    "        ANNSearch(exact_index, num_items, num_candidates),\n",
    "        # Re-fetching user average embeddings keeps modified retrieval from affecting scoring\n",
    "        UserAvgEmbeddingFetcher(model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "items_exact_nonideal_retrieval = improved_filtering_pipeline_builder.build(overrides=items_exact_nonideal_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_exact_nonideal_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(items_exact_nonideal_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(items_exact_nonideal_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item embeddings, approx NN search, no idealization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_approx_nonideal_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        ItemEmbeddingsFetcher(model),\n",
    "        UseItemEmbeddingsAsUserEmbeddings(),\n",
    "        ANNSearch(approx_index, num_items, num_candidates),\n",
    "        # Re-fetching user average embeddings keeps modified retrieval from affecting scoring\n",
    "        UserAvgEmbeddingFetcher(model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "items_approx_nonideal_retrieval = improved_filtering_pipeline_builder.build(overrides=items_approx_nonideal_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:09<00:00,  3.49it/s]\n"
     ]
    }
   ],
   "source": [
    "items_approx_nonideal_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(items_approx_nonideal_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0081\n",
      "Recall: 0.2979\n",
      "NDCG: 0.1870\n"
     ]
    }
   ],
   "source": [
    "print_metrics(items_approx_nonideal_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item + averaged user embeddings, approx NN search, no idealization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_approx_nonideal_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        UserAvgEmbeddingFetcher(model),\n",
    "        ItemEmbeddingsFetcher(model),\n",
    "        UseItemEmbeddingsAsUserEmbeddings(append=True),\n",
    "        ANNSearch(approx_index, num_items, num_candidates),\n",
    "        # Re-fetching user average embeddings keeps modified retrieval from affecting scoring\n",
    "        UserAvgEmbeddingFetcher(model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "both_approx_nonideal_retrieval = improved_filtering_pipeline_builder.build(overrides=both_approx_nonideal_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_approx_nonideal_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(both_approx_nonideal_retrieval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(both_approx_nonideal_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New baseline for further improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stages = RecsPipelineStages(\n",
    "    retrieval = [\n",
    "        ItemEmbeddingsFetcher(model),\n",
    "        UseItemEmbeddingsAsUserEmbeddings(),\n",
    "        ANNSearch(approx_index, num_items, num_candidates),\n",
    "        # Re-fetching user average embeddings keeps modified retrieval from affecting scoring\n",
    "        UserAvgEmbeddingFetcher(model),\n",
    "    ],\n",
    "    filtering = [\n",
    "        BloomFilter(improved_bloom_filters),\n",
    "        CandidatePadding(num_items, num_candidates),\n",
    "    ],\n",
    "    scoring = [\n",
    "        MatrixFactorizationScoring(model),\n",
    "    ],\n",
    "    ordering = [\n",
    "        DitheredOrdering(num_recs, epsilon=dithering_eps),\n",
    "    ]\n",
    ")\n",
    "\n",
    "improved_retrieval_pipeline_builder = RecsPipelineBuilder(defaults=default_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_scoring = improved_retrieval_pipeline_builder.build(overrides=ideal_scoring_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:44<00:00,  3.14it/s]\n"
     ]
    }
   ],
   "source": [
    "ideal_scoring_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(ideal_scoring)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0090\n",
      "Recall: 0.3321\n",
      "NDCG: 0.4041\n"
     ]
    }
   ],
   "source": [
    "print_metrics(ideal_scoring_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_ordering = improved_retrieval_pipeline_builder.build(overrides=ideal_ordering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [04:55<00:00,  3.66it/s]\n"
     ]
    }
   ],
   "source": [
    "ideal_ordering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(ideal_ordering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0081\n",
      "Recall: 0.2979\n",
      "NDCG: 0.2039\n"
     ]
    }
   ],
   "source": [
    "print_metrics(ideal_ordering_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduced dithering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dithering_stages = RecsPipelineStages(\n",
    "    ordering = [\n",
    "        DitheredOrdering(num_recs, epsilon=5.0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reduced_dithering = improved_retrieval_pipeline_builder.build(overrides=reduced_dithering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:06<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "reduced_dithering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(reduced_dithering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0081\n",
      "Recall: 0.2978\n",
      "NDCG: 0.1858\n"
     ]
    }
   ],
   "source": [
    "print_metrics(reduced_dithering_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dithering_stages = RecsPipelineStages(\n",
    "    ordering = [\n",
    "        DitheredOrdering(num_recs, epsilon=3.0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reduced_dithering = improved_retrieval_pipeline_builder.build(overrides=reduced_dithering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:12<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "reduced_dithering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(reduced_dithering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0081\n",
      "Recall: 0.2979\n",
      "NDCG: 0.1903\n"
     ]
    }
   ],
   "source": [
    "print_metrics(reduced_dithering_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dithering_stages = RecsPipelineStages(\n",
    "    ordering = [\n",
    "        DitheredOrdering(num_recs, epsilon=2.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reduced_dithering = improved_retrieval_pipeline_builder.build(overrides=reduced_dithering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:07<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "reduced_dithering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(reduced_dithering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0081\n",
      "Recall: 0.2979\n",
      "NDCG: 0.1919\n"
     ]
    }
   ],
   "source": [
    "print_metrics(reduced_dithering_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dithering_stages = RecsPipelineStages(\n",
    "    ordering = [\n",
    "        DitheredOrdering(num_recs, epsilon=2.0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reduced_dithering = improved_retrieval_pipeline_builder.build(overrides=reduced_dithering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:08<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "reduced_dithering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(reduced_dithering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0081\n",
      "Recall: 0.2979\n",
      "NDCG: 0.1943\n"
     ]
    }
   ],
   "source": [
    "print_metrics(reduced_dithering_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dithering_stages = RecsPipelineStages(\n",
    "    ordering = [\n",
    "        DitheredOrdering(num_recs, epsilon=1.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reduced_dithering = improved_retrieval_pipeline_builder.build(overrides=reduced_dithering_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [05:14<00:00,  3.43it/s]\n"
     ]
    }
   ],
   "source": [
    "reduced_dithering_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(reduced_dithering)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0081\n",
      "Recall: 0.2978\n",
      "NDCG: 0.1981\n"
     ]
    }
   ],
   "source": [
    "print_metrics(reduced_dithering_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring with learned user embeddings (i.e. using the actual model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use improved retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_scoring_stages = RecsPipelineStages(\n",
    "    scoring = [\n",
    "        UserEmbeddingFetcher(model),\n",
    "        MatrixFactorizationScoring(model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "learned_scoring = improved_filtering_pipeline_builder.build(overrides=learned_scoring_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [04:53<00:00,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "learned_scoring_metrics = model.compute_validation_metrics(\n",
    "    tqdm(val_dataloader),\n",
    "    pipeline_fn(learned_scoring)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0128\n",
      "Recall: 0.3535\n",
      "NDCG: 0.1951\n"
     ]
    }
   ],
   "source": [
    "print_metrics(learned_scoring_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
