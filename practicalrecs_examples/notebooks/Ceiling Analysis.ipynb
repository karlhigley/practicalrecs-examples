{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pathlib\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from ranking_metrics_torch.precision_recall import precision_at, recall_at\n",
    "from ranking_metrics_torch.cumulative_gain import ndcg_at\n",
    "from torch_factorization_models.implicit_mf import ImplicitMatrixFactorization\n",
    "from torch_factorization_models.movielens import MovielensDataset, MovielensDataModule\n",
    "\n",
    "from pybloomfilter import BloomFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)  # same seed used to create splits in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens_module = MovielensDataModule(\"/home/karl/Projects/datasets/ml-20m/\")\n",
    "movielens_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens = movielens_module.dataset\n",
    "preprocessor = movielens.preprocessor\n",
    "user_xformer = preprocessor.named_transformers_['user_id']\n",
    "item_xformer = preprocessor.named_transformers_['item_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, benchmark=False, beta1=0.9, beta2=0.999, check_val_every_n_epoch=1, checkpoint_callback=True, default_root_dir=None, deterministic=False, distributed_backend=None, early_stop_callback=False, embedding_dim=32, eval_cutoff=tensor([100]), fast_dev_run=False, gpus=<function Trainer._gpus_arg_default at 0x7faf9e367e50>, gradient_clip_val=0, learning_rate=0.1, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_gpu_memory=None, log_save_interval=100, logger=True, loss='logistic', max_epochs=1000, max_steps=None, min_epochs=1, min_steps=None, momentum=0.9, num_items=20720, num_nodes=1, num_processes=1, num_sanity_val_steps=2, num_users=138287, optimizer='sgd', overfit_batches=0.0, overfit_pct=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=1, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, row_log_interval=50, sync_batchnorm=False, terminate_on_nan=False, test_percent_check=None, tpu_cores=<function Trainer._gpus_arg_default at 0x7faf9e367e50>, track_grad_norm=-1, train_percent_check=None, truncated_bptt_steps=None, use_biases=True, val_check_interval=1.0, val_percent_check=None, weight_decay=0.01, weights_save_path=None, weights_summary='top')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser(add_help=False)\n",
    "parser = Trainer.add_argparse_args(parser)\n",
    "parser = ImplicitMatrixFactorization.add_model_specific_args(parser)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.num_users = 138287\n",
    "args.num_items = 20720\n",
    "# args.use_biases = False\n",
    "args.embedding_dim = 32\n",
    "args.eval_cutoff = th.tensor([100])\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ImplicitMatrixFactorization(args)\n",
    "\n",
    "state_dict = th.load(\"../models/38ov3g28-honest-lake-213.pt\")\n",
    "\n",
    "# preprocessor = state_dict['preprocessor']\n",
    "del state_dict['preprocessor']\n",
    "state_dict['global_bias_idx'] = th.LongTensor([0])\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if th.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "movielens_module.dataset.to_(device=model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = movielens_module.val_dataloader(by_user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = movielens_module.train_dataloader(by_user=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = model.compute_validation_metrics(\n",
    "    val_dataloader,\n",
    "    model.eval_predict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0261\n",
      "Recall: 0.5015\n",
      "NDCG: 0.1874\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {model_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {model_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {model_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Search Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "dim = model.hparams.embedding_dim\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vectors = np.array(model.item_embeddings.weight.cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed: 20720 items\n",
      "Elapsed: 302.9731 ms\n"
     ]
    }
   ],
   "source": [
    "res = faiss.StandardGpuResources()\n",
    "\n",
    "flat_config = faiss.GpuIndexFlatConfig()\n",
    "flat_config.device = 0\n",
    "\n",
    "# Create an index and add item vectors\n",
    "start = time.perf_counter()\n",
    "\n",
    "exact_index = faiss.GpuIndexFlatIP(res, dim, flat_config)  \n",
    "exact_index.add(item_vectors)\n",
    "\n",
    "end = time.perf_counter()\n",
    "\n",
    "elapsed = (end - start) * 1000\n",
    "\n",
    "print(f\"Indexed: {exact_index.ntotal} items\")\n",
    "print(f\"Elapsed: {elapsed:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed: 20720 items\n",
      "Elapsed: 24866.1954 ms\n"
     ]
    }
   ],
   "source": [
    "# Create an index for approximate search with product quantization\n",
    "\n",
    "start = time.perf_counter()\n",
    "res = faiss.StandardGpuResources()\n",
    "\n",
    "approx_index = faiss.index_factory(dim, \"IVF1024,PQ32\", faiss.METRIC_INNER_PRODUCT)\n",
    "co = faiss.GpuClonerOptions()\n",
    "# here we are using a 64-byte PQ, so we must set the lookup tables to\n",
    "# 16 bit float (this is due to the limited temporary memory).\n",
    "# co.useFloat16 = True\n",
    "\n",
    "approx_index = faiss.index_cpu_to_gpu(res, 0, approx_index, co)\n",
    "\n",
    "approx_index.train(item_vectors)\n",
    "approx_index.add(item_vectors)\n",
    "\n",
    "approx_index.nprobe = 30\n",
    "\n",
    "end = time.perf_counter()\n",
    "\n",
    "elapsed = (end - start) * 1000\n",
    "\n",
    "print(f\"Indexed: {approx_index.ntotal} items\")\n",
    "print(f\"Elapsed: {elapsed:.4f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloom filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138287"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 138000\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "bloom_filters = {}\n",
    "\n",
    "for user_id in range(train_dataloader.dataset.num_users):\n",
    "    if user_id % 1000 == 0:\n",
    "        print(f\"\\rUser {user_id}\", sep=\" \", end=\"\", flush=True)\n",
    "    \n",
    "    interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()    \n",
    "    item_ids = interactions.indices()[1]\n",
    "    \n",
    "    bloom = BloomFilter(10, 0.1)\n",
    "    bloom.update(item_ids)\n",
    "        \n",
    "    bloom_filters[user_id] = bloom\n",
    "    \n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_embeddings(model, user_id, item_ids):\n",
    "    item_embeddings = model.item_embeddings.weight[item_ids.to(dtype=th.long)]\n",
    "        \n",
    "    # Use model vector embedding\n",
    "    user_embedding = model.user_embeddings.weight[user_id].unsqueeze(dim=0)\n",
    "        \n",
    "    # Compute user embedding by averaging interacted item embeddings\n",
    "    user_avg_embedding = th.mean(item_embeddings, dim=0).unsqueeze(dim=0)\n",
    "    \n",
    "    return item_embeddings, user_embedding, user_avg_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_embedding_candidates(index, user_embedding, k, num_items):\n",
    "    overfetch = 1.2\n",
    "    num_candidates = int(overfetch * k)\n",
    "    \n",
    "    if not user_embedding.isnan().any():\n",
    "        neighbor_scores, neighbor_indices = index.search(np.array(user_embedding.cpu()), num_candidates)\n",
    "    else:\n",
    "        neighbor_indices = th.randint(num_items, (num_candidates,))\n",
    "    \n",
    "    candidates = th.tensor(neighbor_indices).flatten().unique()\n",
    "    \n",
    "#     if candidates.shape[0] != k:\n",
    "#         print(candidates.shape)\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_candidates(user_id, candidates):\n",
    "    bloom = bloom_filters[user_id]\n",
    "    filtered = list(filter(lambda c: c not in bloom, candidates.numpy()))\n",
    "\n",
    "#     if len(candidates) != len(filtered):\n",
    "#         print(f\"\\nFiltered {len(candidates)} down to {len(filtered)}\")\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_candidates(model, user_embedding, candidates, k, num_items):\n",
    "    candidates = th.tensor(candidates, dtype=th.long)\n",
    "    \n",
    "    # Defensively normalize number of scored candidates to k\n",
    "    if candidates.shape[0] > k:\n",
    "        candidates = candidates[:k]\n",
    "    elif candidates.shape[0] < k:\n",
    "        padding_size = k - candidates.shape[0]\n",
    "        candidates = th.cat([candidates, th.randint(num_items, (padding_size,))])\n",
    "    \n",
    "    item_vectors = model.item_embeddings.weight.squeeze()\n",
    "    item_biases = model.item_biases.weight.squeeze()\n",
    "\n",
    "    scores = model._similarity_scores(\n",
    "        user_embedding, th.empty((1, 1)), item_vectors, item_biases\n",
    "    ).flatten()\n",
    " \n",
    "    masked_scores = th.empty_like(scores).fill_(-float(\"inf\"))\n",
    "    masked_scores[candidates] = scores[candidates]\n",
    "    \n",
    "    return masked_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dither_scores(scores, k, epsilon=1.5):\n",
    "    log_ranks = th.log(th.arange(k) + 1.0)\n",
    "    std_dev = th.sqrt(th.log(th.tensor(epsilon)))\n",
    "    \n",
    "    # Compute dithered scores based on item ranks\n",
    "    dithered_scores = -(log_ranks + th.randn_like(log_ranks) * std_dev)\n",
    "        \n",
    "    # Replace raw scores with dithered scores\n",
    "    _, topk_indices = th.topk(scores, k)\n",
    "    scores[topk_indices] = dithered_scores.to(device=scores.device)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(user_ids, num_items):\n",
    "    k = 250\n",
    "    dithering_eps = 1.5\n",
    "    \n",
    "    user_scores = []\n",
    "    for user_id in user_ids:\n",
    "        if user_id % 1000 == 0:\n",
    "            print(f\"\\rUser {user_id}\", sep=\" \", end=\"\", flush=True)\n",
    "        \n",
    "        interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        item_ids = interactions.indices()[1]\n",
    "        \n",
    "        item_embeddings, user_embedding, user_avg_embedding = \\\n",
    "                fetch_embeddings(model, user_id, item_ids)\n",
    "        \n",
    "        candidates = user_embedding_candidates(approx_index, user_avg_embedding, k, args.num_items)\n",
    "        filtered = filter_candidates(user_id.cpu().item(), candidates)\n",
    "        raw_scores = score_candidates(model, user_avg_embedding, filtered, k, args.num_items)\n",
    "        scores = dither_scores(raw_scores, k, dithering_eps)\n",
    "        \n",
    "        user_scores.append(scores)\n",
    "        \n",
    "    return th.stack(user_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "User 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-356e89864172>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidates = th.tensor(neighbor_indices).flatten().unique()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 138000\n",
      "Precision: 0.0120\n",
      "Recall: 0.2878\n",
      "NDCG: 0.1056\n"
     ]
    }
   ],
   "source": [
    "pipeline_metrics = model.compute_validation_metrics(\n",
    "    val_dataloader,\n",
    "    full_pipeline\n",
    ")\n",
    "\n",
    "print(f\"\\nPrecision: {pipeline_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {pipeline_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {pipeline_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_candidates(index, user_embedding, user_id, k, num_items):\n",
    "#     print(user_id.item())\n",
    "#     print(val_dataloader.dataset[user_id.item()])  \n",
    "\n",
    "    val_interactions = val_dataloader.dataset[user_id.item()][\"interactions\"].coalesce()\n",
    "    val_item_ids = val_interactions.indices()[1]\n",
    "    \n",
    "#     print(val_item_ids)\n",
    "    \n",
    "    if not user_embedding.isnan().any():\n",
    "        neighbor_scores, neighbor_indices = index.search(np.array(user_embedding.cpu()), k)\n",
    "    else:\n",
    "        neighbor_indices = th.randint(num_items, (k,))\n",
    "    \n",
    "    neighbor_set = set(neighbor_indices.flatten().tolist())\n",
    "    val_set = set(val_item_ids.flatten().tolist())\n",
    "    padding_set = neighbor_set - val_set\n",
    "    \n",
    "    ideal_indices = list(val_set) + list(padding_set)\n",
    "    \n",
    "#     print(f\"Neighbor set: {neighbor_set}\")\n",
    "#     print(f\"Validation set: {val_set}\")\n",
    "#     print(f\"Padding set: {padding_set}\")\n",
    "#     print(f\"Combined: {ideal_indices[:10]}\")\n",
    "    \n",
    "    candidates = th.tensor(ideal_indices).flatten().unique()\n",
    "    \n",
    "#     if candidates.shape[0] < k:\n",
    "#         print(candidates.shape)\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_retrieval(user_ids, num_items):\n",
    "    k = 250\n",
    "    dithering_eps = 1.5\n",
    "    \n",
    "    user_scores = []\n",
    "    for user_id in user_ids:\n",
    "        if user_id % 1000 == 0:\n",
    "            print(f\"\\rUser {user_id}\", sep=\" \", end=\"\", flush=True)\n",
    "        \n",
    "        interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        item_ids = interactions.indices()[1]\n",
    "        \n",
    "        item_embeddings, user_embedding, user_avg_embedding = \\\n",
    "                fetch_embeddings(model, user_id, item_ids)\n",
    "        \n",
    "        candidates = ideal_candidates(approx_index, user_avg_embedding, user_id, k, args.num_items)\n",
    "        filtered = filter_candidates(user_id.cpu().item(), candidates)\n",
    "        raw_scores = score_candidates(model, user_avg_embedding, filtered, k, num_items)\n",
    "        scores = dither_scores(raw_scores, k, dithering_eps)\n",
    "        \n",
    "        user_scores.append(scores)\n",
    "        \n",
    "    return th.stack(user_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 138000\n",
      "Precision: 0.0148\n",
      "Recall: 0.3287\n",
      "NDCG: 0.1193\n"
     ]
    }
   ],
   "source": [
    "ideal_retrieval_metrics = model.compute_validation_metrics(\n",
    "    val_dataloader,\n",
    "    ideal_retrieval\n",
    ")\n",
    "\n",
    "print(f\"\\nPrecision: {ideal_retrieval_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {ideal_retrieval_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {ideal_retrieval_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_filtering(user_ids, num_items):\n",
    "    k = 250\n",
    "    dithering_eps = 1.5\n",
    "    \n",
    "    user_scores = []\n",
    "    for user_id in user_ids:\n",
    "        if user_id % 1000 == 0:\n",
    "            print(f\"\\rUser {user_id}\", sep=\" \", end=\"\", flush=True)\n",
    "        \n",
    "        interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        item_ids = interactions.indices()[1]\n",
    "        \n",
    "        item_embeddings, user_embedding, user_avg_embedding = \\\n",
    "                fetch_embeddings(model, user_id, item_ids)\n",
    "        \n",
    "        candidates = user_embedding_candidates(approx_index, user_avg_embedding, k, args.num_items)\n",
    "#         filtered = filter_candidates(user_id.cpu().item(), candidates)\n",
    "        raw_scores = score_candidates(model, user_avg_embedding, candidates, k, args.num_items)\n",
    "        scores = dither_scores(raw_scores, k, dithering_eps)\n",
    "        \n",
    "        user_scores.append(scores)\n",
    "        \n",
    "    return th.stack(user_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "User 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-e6a1c155941d>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidates = th.tensor(candidates, dtype=th.long)\n",
      "<ipython-input-19-356e89864172>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidates = th.tensor(neighbor_indices).flatten().unique()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 138000\n",
      "Precision: 0.0183\n",
      "Recall: 0.3351\n",
      "NDCG: 0.1260\n"
     ]
    }
   ],
   "source": [
    "ideal_filtering_metrics = model.compute_validation_metrics(\n",
    "    val_dataloader,\n",
    "    ideal_filtering\n",
    ")\n",
    "\n",
    "print(f\"\\nPrecision: {ideal_filtering_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {ideal_filtering_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {ideal_filtering_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_scoring(user_ids, num_items):\n",
    "    k = 250\n",
    "    dithering_eps = 1.5\n",
    "    \n",
    "    user_scores = []\n",
    "    for user_id in user_ids:\n",
    "        if user_id % 1000 == 0:\n",
    "            print(f\"\\rUser {user_id}\", sep=\" \", end=\"\", flush=True)\n",
    "        \n",
    "        interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        item_ids = interactions.indices()[1]\n",
    "        \n",
    "        item_embeddings, user_embedding, user_avg_embedding = \\\n",
    "                fetch_embeddings(model, user_id, item_ids)\n",
    "        \n",
    "        candidates = user_embedding_candidates(approx_index, user_avg_embedding, k, args.num_items)\n",
    "        filtered = filter_candidates(user_id.cpu().item(), candidates)\n",
    "        raw_scores = score_candidates(model, user_avg_embedding, filtered, k, args.num_items)\n",
    "        \n",
    "        # Move interacted items from validation set to the top\n",
    "        val_interactions = val_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        val_item_ids = val_interactions.indices()[1]\n",
    "        boosted_scores = raw_scores.clone().detach()\n",
    "        boosted_scores[val_item_ids] += 10.0\n",
    "        \n",
    "        scores = dither_scores(boosted_scores, k, dithering_eps)\n",
    "        \n",
    "        user_scores.append(scores)\n",
    "        \n",
    "    return th.stack(user_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "User 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-356e89864172>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidates = th.tensor(neighbor_indices).flatten().unique()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 138000\n",
      "Precision: 0.0174\n",
      "Recall: 0.4300\n",
      "NDCG: 0.4502\n"
     ]
    }
   ],
   "source": [
    "ideal_scoring_metrics = model.compute_validation_metrics(\n",
    "    val_dataloader,\n",
    "    ideal_scoring\n",
    ")\n",
    "\n",
    "print(f\"\\nPrecision: {ideal_scoring_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {ideal_scoring_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {ideal_scoring_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_ordering(user_ids, num_items):\n",
    "    k = 250\n",
    "    dithering_eps = 1.5\n",
    "    \n",
    "    user_scores = []\n",
    "    for user_id in user_ids:\n",
    "        if user_id % 1000 == 0:\n",
    "            print(f\"\\rUser {user_id}\", sep=\" \", end=\"\", flush=True)\n",
    "        \n",
    "        interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        item_ids = interactions.indices()[1]\n",
    "        \n",
    "        item_embeddings, user_embedding, user_avg_embedding = \\\n",
    "                fetch_embeddings(model, user_id, item_ids)\n",
    "        \n",
    "        candidates = user_embedding_candidates(approx_index, user_avg_embedding, k, args.num_items)\n",
    "        filtered = filter_candidates(user_id.cpu().item(), candidates)\n",
    "        raw_scores = score_candidates(model, user_avg_embedding, filtered, k, args.num_items)\n",
    "#         scores = dither_scores(raw_scores, k, dithering_eps)\n",
    "        \n",
    "        user_scores.append(raw_scores)\n",
    "        \n",
    "    return th.stack(user_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "User 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-356e89864172>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidates = th.tensor(neighbor_indices).flatten().unique()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 138000\n",
      "Precision: 0.0132\n",
      "Recall: 0.3159\n",
      "NDCG: 0.1144\n"
     ]
    }
   ],
   "source": [
    "ideal_ordering_metrics = model.compute_validation_metrics(\n",
    "    val_dataloader,\n",
    "    ideal_ordering\n",
    ")\n",
    "\n",
    "print(f\"\\nPrecision: {ideal_ordering_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {ideal_ordering_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {ideal_ordering_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_embedding_candidates(index, item_embeddings, k, num_items):\n",
    "    if len(item_embeddings) > 0:\n",
    "        neighbors_per = max(1, k // max(1,len(item_embeddings)))\n",
    "        neighbor_scores, neighbor_indices = index.search(np.array(item_embeddings.cpu()), neighbors_per)\n",
    "    else:\n",
    "        neighbor_indices = th.randint(num_items, (k,))\n",
    "        \n",
    "    return th.tensor(neighbor_indices).flatten().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_retrieval(user_ids, num_items):\n",
    "    k = 250\n",
    "    dithering_eps = 1.5\n",
    "    \n",
    "    user_scores = []\n",
    "    for user_id in user_ids:\n",
    "        if user_id % 1000 == 0:\n",
    "            print(f\"\\rUser {user_id}\", sep=\" \", end=\"\", flush=True)\n",
    "        \n",
    "        interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        item_ids = interactions.indices()[1]\n",
    "        \n",
    "        item_embeddings, user_embedding, user_avg_embedding = \\\n",
    "                fetch_embeddings(model, user_id, item_ids)\n",
    "        \n",
    "        candidates = item_embedding_candidates(approx_index, item_embeddings, k, args.num_items)\n",
    "        filtered = filter_candidates(user_id.cpu().item(), candidates)\n",
    "        raw_scores = score_candidates(model, user_avg_embedding, filtered, k, args.num_items)\n",
    "        scores = dither_scores(raw_scores, k, dithering_eps)\n",
    "        \n",
    "        user_scores.append(scores)\n",
    "        \n",
    "    return th.stack(user_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "User 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-503638a3b9d1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return th.tensor(neighbor_indices).flatten().unique()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 138000\n",
      "Precision: 0.0069\n",
      "Recall: 0.1966\n",
      "NDCG: 0.0743\n"
     ]
    }
   ],
   "source": [
    "item_based_retrieval_metrics = model.compute_validation_metrics(\n",
    "    val_dataloader,\n",
    "    item_based_retrieval\n",
    ")\n",
    "\n",
    "print(f\"\\nPrecision: {item_based_retrieval_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {item_based_retrieval_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {item_based_retrieval_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_retrieval_ideal_filtering(user_ids, num_items):\n",
    "    k = 250\n",
    "    dithering_eps = 1.5\n",
    "    \n",
    "    user_scores = []\n",
    "    for user_id in user_ids:\n",
    "        if user_id % 1000 == 0:\n",
    "            print(f\"\\rUser {user_id}\", sep=\" \", end=\"\", flush=True)\n",
    "        \n",
    "        interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        item_ids = interactions.indices()[1]\n",
    "        \n",
    "        item_embeddings, user_embedding, user_avg_embedding = \\\n",
    "                fetch_embeddings(model, user_id, item_ids)\n",
    "        \n",
    "        candidates = item_embedding_candidates(approx_index, item_embeddings, k, args.num_items)\n",
    "#         filtered = filter_candidates(user_id.cpu().item(), candidates)\n",
    "        raw_scores = score_candidates(model, user_avg_embedding, candidates, k, args.num_items)\n",
    "        scores = dither_scores(raw_scores, k, dithering_eps)\n",
    "        \n",
    "        user_scores.append(scores)\n",
    "        \n",
    "    return th.stack(user_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "User 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-e6a1c155941d>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidates = th.tensor(candidates, dtype=th.long)\n",
      "<ipython-input-34-503638a3b9d1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return th.tensor(neighbor_indices).flatten().unique()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 138000\n",
      "Precision: 0.0086\n",
      "Recall: 0.2195\n",
      "NDCG: 0.0827\n"
     ]
    }
   ],
   "source": [
    "item_based_retrieval_ideal_filtering_metrics = model.compute_validation_metrics(\n",
    "    val_dataloader,\n",
    "    item_based_retrieval_ideal_filtering\n",
    ")\n",
    "\n",
    "print(f\"\\nPrecision: {item_based_retrieval_ideal_filtering_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {item_based_retrieval_ideal_filtering_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {item_based_retrieval_ideal_filtering_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_retrieval_ideal_scoring(user_ids, num_items):\n",
    "    k = 250\n",
    "    dithering_eps = 1.5\n",
    "    \n",
    "    user_scores = []\n",
    "    for user_id in user_ids:\n",
    "        if user_id % 1000 == 0:\n",
    "            print(f\"\\rUser {user_id}\", sep=\" \", end=\"\", flush=True)\n",
    "        \n",
    "        interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        item_ids = interactions.indices()[1]\n",
    "        \n",
    "        item_embeddings, user_embedding, user_avg_embedding = \\\n",
    "                fetch_embeddings(model, user_id, item_ids)\n",
    "        \n",
    "        candidates = item_embedding_candidates(approx_index, item_embeddings, k, args.num_items)\n",
    "        filtered = filter_candidates(user_id.cpu().item(), candidates)\n",
    "        raw_scores = score_candidates(model, user_avg_embedding, filtered, k, args.num_items)\n",
    "        scores = dither_scores(raw_scores, k, dithering_eps)\n",
    "        \n",
    "        # Move interacted items from validation set to the top\n",
    "        val_interactions = val_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        val_item_ids = val_interactions.indices()[1]\n",
    "        boosted_scores = raw_scores.clone().detach()\n",
    "        boosted_scores[val_item_ids] += 10.0\n",
    "        \n",
    "        user_scores.append(scores)\n",
    "        \n",
    "    return th.stack(user_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "User 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-503638a3b9d1>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return th.tensor(neighbor_indices).flatten().unique()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 133000"
     ]
    }
   ],
   "source": [
    "item_based_retrieval_ideal_scoring_metrics = model.compute_validation_metrics(\n",
    "    val_dataloader,\n",
    "    item_based_retrieval_ideal_scoring\n",
    ")\n",
    "\n",
    "print(f\"\\nPrecision: {item_based_retrieval_ideal_scoring_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {item_based_retrieval_ideal_scoring_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {item_based_retrieval_ideal_scoring_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_retrieval_ideal_ordering(user_ids, num_items):\n",
    "    k = 250\n",
    "    dithering_eps = 1.5\n",
    "    \n",
    "    user_scores = []\n",
    "    for user_id in user_ids:\n",
    "        if user_id % 1000 == 0:\n",
    "            print(f\"\\rUser {user_id}\", sep=\" \", end=\"\", flush=True)\n",
    "        \n",
    "        interactions = train_dataloader.dataset[user_id][\"interactions\"].coalesce()\n",
    "        item_ids = interactions.indices()[1]\n",
    "        \n",
    "        item_embeddings, user_embedding, user_avg_embedding = \\\n",
    "                fetch_embeddings(model, user_id, item_ids)\n",
    "        \n",
    "        candidates = item_embedding_candidates(approx_index, item_embeddings, k, args.num_items)\n",
    "        filtered = filter_candidates(user_id.cpu().item(), candidates)\n",
    "        raw_scores = score_candidates(model, user_avg_embedding, filtered, k, args.num_items)\n",
    "#         scores = dither_scores(raw_scores, k, dithering_eps)\n",
    "        \n",
    "        user_scores.append(raw_scores)\n",
    "        \n",
    "    return th.stack(user_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_retrieval_ideal_ordering_metrics = model.compute_validation_metrics(\n",
    "    val_dataloader,\n",
    "    item_based_retrieval_ideal_ordering\n",
    ")\n",
    "\n",
    "print(f\"\\nPrecision: {item_based_retrieval_ideal_ordering_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {item_based_retrieval_ideal_ordering_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {item_based_retrieval_ideal_ordering_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try out better Bloom filter parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try out using the learned user embeddings for scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try reducing the dithering eps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
