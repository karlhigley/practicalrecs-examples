{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import sklearn as sk\n",
    "\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from ranking_metrics_torch.precision_recall import precision_at, recall_at\n",
    "from ranking_metrics_torch.cumulative_gain import ndcg_at\n",
    "from torch_factorization_models.implicit_mf import ImplicitMatrixFactorization\n",
    "from torch_factorization_models.movielens import MovielensDataset, MovielensDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)  # same seed used to create splits in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens_module = MovielensDataModule(\"/home/karl/Projects/datasets/ml-20m/\")\n",
    "movielens_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens = movielens_module.dataset\n",
    "preprocessor = movielens.preprocessor\n",
    "user_xformer = preprocessor.named_transformers_['user_id']\n",
    "item_xformer = preprocessor.named_transformers_['item_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, benchmark=False, beta1=0.9, beta2=0.999, check_val_every_n_epoch=1, checkpoint_callback=True, default_root_dir=None, deterministic=False, distributed_backend=None, early_stop_callback=False, embedding_dim=32, eval_cutoff=tensor([100]), fast_dev_run=False, gpus=<function Trainer._gpus_arg_default at 0x7f65551b3040>, gradient_clip_val=0, learning_rate=0.1, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_gpu_memory=None, log_save_interval=100, logger=True, loss='logistic', max_epochs=1000, max_steps=None, min_epochs=1, min_steps=None, momentum=0.9, num_items=20720, num_nodes=1, num_processes=1, num_sanity_val_steps=2, num_users=138287, optimizer='sgd', overfit_batches=0.0, overfit_pct=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=1, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, row_log_interval=50, sync_batchnorm=False, terminate_on_nan=False, test_percent_check=None, tpu_cores=<function Trainer._gpus_arg_default at 0x7f65551b3040>, track_grad_norm=-1, train_percent_check=None, truncated_bptt_steps=None, use_biases=True, val_check_interval=1.0, val_percent_check=None, weight_decay=0.01, weights_save_path=None, weights_summary='top')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser(add_help=False)\n",
    "parser = Trainer.add_argparse_args(parser)\n",
    "parser = ImplicitMatrixFactorization.add_model_specific_args(parser)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.num_users = 138287\n",
    "args.num_items = 20720\n",
    "# args.use_biases = False\n",
    "args.embedding_dim = 32\n",
    "args.eval_cutoff = th.tensor([100])\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ImplicitMatrixFactorization(args)\n",
    "\n",
    "state_dict = th.load(\"../models/38ov3g28-honest-lake-213.pt\")\n",
    "\n",
    "# preprocessor = state_dict['preprocessor']\n",
    "del state_dict['preprocessor']\n",
    "state_dict['global_bias_idx'] = th.LongTensor([0])\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if th.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens_module.dataset.to_(device=model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = movielens_module.val_dataloader(by_user=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_predict(user_ids, num_items):\n",
    "    global model\n",
    "    return th.rand((len(user_ids), num_items), device=model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karl/.pyenv/versions/3.8.3/envs/factorization-models/lib/python3.8/site-packages/ranking_metrics_torch/precision_recall.py:52: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  rel_indices = (num_relevant != 0).nonzero()\n"
     ]
    }
   ],
   "source": [
    "random_metrics = model.compute_validation_metrics(\n",
    "    dataloader,\n",
    "    random_predict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0004\n",
      "Recall: 0.0049\n",
      "NDCG: 0.0018\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {random_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {random_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {random_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset_items = movielens.item_ids[movielens_module.training.indices]\n",
    "unique, counts = np.unique(training_subset_items.cpu(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_scores = th.zeros(movielens.num_items)\n",
    "\n",
    "for index, count in dict(zip(unique, counts)).items():\n",
    "    pop_scores[index] = count\n",
    "    \n",
    "pop_scores /= np.amax(counts)\n",
    "\n",
    "pop_scores = pop_scores.to(device=model.device)\n",
    "\n",
    "def pop_predict(user_ids, num_items):\n",
    "    return pop_scores.expand(len(user_ids), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_metrics = model.compute_validation_metrics(\n",
    "    dataloader,\n",
    "    pop_predict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0187\n",
      "Recall: 0.3019\n",
      "NDCG: 0.1287\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {pop_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {pop_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {pop_metrics['ndcg']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = model.compute_validation_metrics(\n",
    "    dataloader,\n",
    "    model.eval_predict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0261\n",
      "Recall: 0.5017\n",
      "NDCG: 0.1875\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {model_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {model_metrics['recall']:.4f}\")\n",
    "print(f\"NDCG: {model_metrics['ndcg']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
